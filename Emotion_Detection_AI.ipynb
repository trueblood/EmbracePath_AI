{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1b0b-4831-43ed-adf0-f1273b131f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453edc29-adbf-4eb2-9932-5c63d642cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cd0011-5c3b-4f17-a0a9-17408545f33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load CSV data\n",
    "\n",
    "# Assuming gcsfs is installed and configured\n",
    "csv_path = 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/data.csv'\n",
    "\n",
    "# Use pandas to directly read from GCS\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Drop the first column if it is unnamed or not required\n",
    "if 'Unnamed: 0' in df.columns or df.columns[0] == 'path':  # Check if the first column is 'path' or an unnamed index\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "# Show the first few rows to verify\n",
    "print(df.head())\n",
    "\n",
    "# Create a dictionary mapping filenames to emotions\n",
    "emotion_dict = pd.Series(df.label.values, index=df.path.apply(lambda x: x.split('/')[-1])).to_dict()\n",
    "# print(\"emotion_dict is\", emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c927664-b1f0-46e5-9308-86cd1c521efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "\n",
    "load_dotenv()  # Load the environment variables from the .env file\n",
    "\n",
    "GOOGLE_KEY_PATH = os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "GOOGLE_BUCKET_NAME = os.getenv('GOOGLE_STORAGE_BUCKET')\n",
    "\n",
    "# Set the GOOGLE_APPLICATION_CREDENTIALS environment variable\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = key_path\n",
    "\n",
    "# Initialize the Google Cloud Storage client\n",
    "client = storage.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c28306-cf60-414e-bab1-9e0b38a066b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_image_to_category_label(blob, emotion_dict):\n",
    "    \"\"\"Reads an image and its label from Google Cloud Storage.\"\"\"\n",
    "    image_data = blob.download_as_bytes()\n",
    "    image_array = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Extract the filename from the blob and get the corresponding emotion\n",
    "    filename = blob.name.split('/')[-1]  # Extract filename from path\n",
    "    emotion = emotion_dict.get(filename, \"Unknown\")  # Fetch emotion label using filename\n",
    "    \n",
    "    return img, emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56bd79c-ad75-4831-890b-ce2a51e24e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = client.bucket(bucket_name)\n",
    "# Example: List files in the bucket\n",
    "blobs = bucket.list_blobs()\n",
    "# for blob in blobs:\n",
    "#     print(blob.name)\n",
    "# Define the path to the image file\n",
    "blob_path = 'DataSets/FacialEmotionRecognitionImageDataset_v1/'\n",
    "\n",
    "# Get the blobs in the directory\n",
    "blobs = list(bucket.list_blobs(prefix=blob_path))\n",
    "blobs = [blob for blob in blobs if 'Ahegao' not in blob.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3499c6-731e-46ce-8a3f-46f9d10423b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read image from GCS\n",
    "def read_image_from_gcs(blob):\n",
    "    \"\"\"Reads an image from Google Cloud Storage into a numpy array.\"\"\"\n",
    "    image_data = blob.download_as_bytes()\n",
    "    image_array = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd0ccf4-55b5-42c6-a5d9-c5b325df5c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the file count and show random sample of images from the dataset\n",
    "print(f\"File count: {len(blobs)}\")\n",
    "\n",
    "# Display a random set of images\n",
    "num_images = 3\n",
    "num_samples = 3\n",
    "plt.figure(figsize=(13, 13))\n",
    "\n",
    "for i in range(num_images):\n",
    "    for j in range(num_samples):\n",
    "        random_blob = np.random.choice(blobs)  # Make sure 'blobs' contains the list of all blob objects you want to choose from\n",
    "        img, emotion_label = match_image_to_category_label(random_blob, emotion_dict)\n",
    "        \n",
    "        plt.subplot(num_images, num_samples, i * num_samples + j + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(emotion_label)  # Display the emotion label as the title\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6ba1ff-8533-4757-8963-f1d5234c4828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code streams from google storage bucket\n",
    "# # Using glob to list all JPEG files in the specific GCS bucket directory\n",
    "# filenames = tf.io.gfile.glob('gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_V1/*.jpg')\n",
    "\n",
    "# # Calculate the total number of image files\n",
    "# total_images = len(filenames)\n",
    "\n",
    "# # Print the total number of image files\n",
    "# print(\"Total number of image files:\", total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7c5c1-a8d1-4639-a953-52a2164a362d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
