{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d29fe896-dd46-4f53-92e8-b6ddb52df09a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 5s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file:///tmp/Emotion_Detection_AI_20240803_041610_v1.h5 [Content-Type=application/x-hdf5]...\n",
      "\\ [1 files][148.1 MiB/148.1 MiB]                                                \n",
      "Operation completed over 1 objects/148.1 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully to gs://storage_for_all/models/Emotion_Detection_AI_20240803_041610_v1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://storage_for_all/models/Emotion_Detection_AI_20240803_040927_v1.h5...\n",
      "\\ [1 files][148.1 MiB/148.1 MiB]                                                \n",
      "Operation completed over 1 objects/148.1 MiB.                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from gs://storage_for_all/models/Emotion_Detection_AI_20240803_040927_v1.h5\n",
      "Model loaded into TensorFlow\n",
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 152\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# Example usage    \u001b[39;00m\n\u001b[1;32m    151\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Surprise/1bd930d6a1c717c11be33db74823f661cb53f86cbba1d3d1f336cdf9~12fffff.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 152\u001b[0m     predicted_emotion \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_emotion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Emotion:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_emotion)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# tf.keras.models.save_model(model, full_model_path, save_format='h5')\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# predicted_emotion = predict_emotion('gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Surprise/1bd930d6a1c717c11be33db74823f661cb53f86cbba1d3d1f336cdf9~12fffff.jpg')\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# print(\"Predicted Emotion:\", predicted_emotion)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 142\u001b[0m, in \u001b[0;36mpredict_emotion\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m    139\u001b[0m emotion_label \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform([predicted_class])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# Display the image with the predicted emotion\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    143\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(image[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    144\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Emotion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00memotion_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/data.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "df = df.loc[:35]# Adjust this part to ensure correct path handling:\n",
    "\n",
    "# Adjust paths\n",
    "df['path'] = df['path'].apply(lambda x: f\"gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/{x.split('/')[-2]}/{x.split('/')[-1]}\")\n",
    "\n",
    "# Label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df['label'])\n",
    "one_hot_encoded_labels = to_categorical(integer_encoded)\n",
    "\n",
    "# Dataset preparation function\n",
    "def load_image(file_path, label):\n",
    "    \"\"\"Load and preprocess images from file paths.\"\"\"\n",
    "    try:\n",
    "        image_data = tf.io.read_file(file_path)\n",
    "        image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])  # Resize as needed\n",
    "        return image, label\n",
    "    except tf.errors.NotFoundError:\n",
    "        print(f\"Failed to load image at: {file_path}\")\n",
    "        return None, label  # Handle missing files gracefully\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((df['path'].tolist(), one_hot_encoded_labels))\n",
    "full_dataset = full_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "full_dataset = full_dataset.filter(lambda x, y: x is not None and y is not None)\n",
    "full_dataset = full_dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# Split dataset into training and validation\n",
    "dataset_size = len(df)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "val_dataset = full_dataset.skip(train_size).take(val_size)\n",
    "\n",
    "# Model definition\n",
    "def tf_model(num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 3)),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Create a new directory for models if it doesn't exist\n",
    "model_dir = \"gs://storage_for_all/models\"\n",
    "full_model_path = f\"{model_dir}/{model_name}\"\n",
    "\n",
    "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
    "model = tf_model(num_classes)\n",
    "\n",
    "# Model training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    validation_data=val_dataset,\n",
    "    use_multiprocessing=False,\n",
    "    workers=1\n",
    ")\n",
    "\n",
    "# Define the model name and local path\n",
    "model_name = f\"Emotion_Detection_AI_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_v1.h5\"\n",
    "local_model_path = f\"/tmp/{model_name}\"\n",
    "\n",
    "# Save the model locally\n",
    "model.save(local_model_path, save_format='h5')\n",
    "\n",
    "# Copy the model to Google Cloud Storage\n",
    "gcs_model_path = f\"gs://storage_for_all/models/{model_name}\"\n",
    "os.system(f\"gsutil cp {local_model_path} {gcs_model_path}\")\n",
    "\n",
    "# Verify the model was copied\n",
    "if tf.io.gfile.exists(gcs_model_path):\n",
    "    print(f\"Model saved successfully to {gcs_model_path}\")\n",
    "else:\n",
    "    print(\"Failed to save the model to GCS\")\n",
    "\n",
    "    \n",
    "# Define the model name and GCS path\n",
    "model_name = \"Emotion_Detection_AI_20240803_040927_v1.h5\"  # Replace with your actual model name\n",
    "gcs_model_path = f\"gs://storage_for_all/models/{model_name}\"\n",
    "local_model_path = f\"/tmp/{model_name}\"\n",
    "\n",
    "# Copy the model from GCS to local path\n",
    "os.system(f\"gsutil cp {gcs_model_path} {local_model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Verify the model was copied\n",
    "if not tf.io.gfile.exists(local_model_path):\n",
    "    print(\"Failed to load the model from GCS\")\n",
    "else:\n",
    "    print(f\"Model loaded successfully from {gcs_model_path}\")\n",
    "\n",
    "    # Load the model from local path\n",
    "    model = tf.keras.models.load_model(local_model_path)\n",
    "    print(\"Model loaded into TensorFlow\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    #test_loss, test_acc = model.evaluate(val_dataset, verbose=0)  # Set verbose to 0 to disable progress bar\n",
    "    #print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "    # Function to predict emotion and display the image\n",
    "    def predict_emotion(image_path):\n",
    "        image_data = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.expand_dims(image, 0)  # Make batch of 1\n",
    "\n",
    "        predictions = model.predict(image)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        emotion_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "\n",
    "        # Display the image with the predicted emotion\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(image[0].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Predicted Emotion: {emotion_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        return emotion_label\n",
    "\n",
    "    # Example usage    \n",
    "    image_path = 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Surprise/1bd930d6a1c717c11be33db74823f661cb53f86cbba1d3d1f336cdf9~12fffff.jpg'\n",
    "    predicted_emotion = predict_emotion(image_path)\n",
    "    print(\"Predicted Emotion:\", predicted_emotion)\n",
    "\n",
    "# tf.keras.models.save_model(model, full_model_path, save_format='h5')\n",
    "\n",
    "\n",
    "\n",
    "# import datetime\n",
    "\n",
    "\n",
    "\n",
    "# # Define the model name\n",
    "# model_name = f\"Emotion_Detection_AI_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_v1\"\n",
    "\n",
    "# # Create a new directory for models if it doesn't exist\n",
    "# model_dir = \"gs://storage_for_all/models\"\n",
    "# full_model_path = f\"{model_dir}/{model_name}\"\n",
    "\n",
    "# # Save the model to a Google Cloud Storage bucket\n",
    "# tf.keras.models.save_model(model, full_model_path, save_format='h5')\n",
    "\n",
    "# # Load the model from a Google Cloud Storage bucket\n",
    "# loaded_model = tf.keras.models.load_model(full_model_path)\n",
    "\n",
    "# # Print confirmation\n",
    "# print(\"Model saved and loaded successfully.\")\n",
    "# #tf.io.gfile.makedirs(model_dir)\n",
    "\n",
    "# # Save the model to the new directory\n",
    "# model.save(f\"{model_dir}/{model_name}\")\n",
    "\n",
    "\n",
    "\n",
    "# # Save the model to a Google Cloud Storage bucket\n",
    "# with tf.io.gfile.GFile(f\"gs://storage_for_all/{model_name}\", \"wb\") as f:\n",
    "#     tf.keras.models.save_model(model, f, save_format='h5')\n",
    "\n",
    "# # Load the model from a Google Cloud Storage bucket\n",
    "# with tf.io.gfile.GFile(f\"gs://storage_for_all/{model_name}\", \"rb\") as f:\n",
    "#     model = tf.keras.models.load_model(f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "# model_save_path = \"/models/emotion_detection_cnn_v1\"\n",
    "# model.save(model_save_path)\n",
    "\n",
    "# # Evaluate the model\n",
    "# test_loss, test_acc = model.evaluate(val_dataset)\n",
    "# print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# # Prediction function\n",
    "# def predict_emotion(image_path):\n",
    "#     img, _ = load_image(image_path, None)\n",
    "#     img = tf.expand_dims(img, 0)  # Make batch of 1\n",
    "#     predictions = model.predict(img)\n",
    "#     predicted_class = tf.argmax(predictions[0]).numpy()\n",
    "#     return label_encoder.inverse_transform([predicted_class])[0]  # Assuming labels are ordered\n",
    "\n",
    "# # Example usage\n",
    "# predicted_emotion = predict_emotion('gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Surprise/1bd930d6a1c717c11be33db74823f661cb53f86cbba1d3d1f336cdf9~12fffff.jpg')\n",
    "# print(\"Predicted Emotion:\", predicted_emotion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cdc167-62d8-4d81-bcbe-5ad76ea189aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
