{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d677b5-e6b7-4a8d-acad-9b6613602ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import psutil\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load CSV data\n",
    "csv_path = 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/data.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df[df['label'].isin(['Happy', 'Sad', 'Angry'])]\n",
    "\n",
    "# Display the total number of unique labels in the 'label' column\n",
    "unique_labels = df['label'].unique()\n",
    "total_unique_labels = len(unique_labels)\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "dataset_size = len(df)\n",
    "df = df.sample(dataset_size).reset_index(drop=True) # limit number of values and shuffle\n",
    "\n",
    "# Adjust paths\n",
    "df['path'] = df['path'].apply(lambda x: f\"gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/{x.split('/')[-2]}/{x.split('/')[-1]}\")\n",
    "\n",
    "# Label encoding for ML processing\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df['label'])\n",
    "one_hot_encoded_labels = to_categorical(integer_encoded)\n",
    "\n",
    "# Dataset preparation function\n",
    "def load_image(file_path, label):\n",
    "    \"\"\"Load and preprocess images from file paths, handling different formats based on extensions.\"\"\"\n",
    "    try:\n",
    "        image_data = tf.io.read_file(file_path)\n",
    "        \n",
    "        # Conditionally decode based on the file extension\n",
    "        def decode_jpeg():\n",
    "            return tf.image.decode_jpeg(image_data, channels=3)\n",
    "        \n",
    "        def decode_png():\n",
    "            return tf.image.decode_png(image_data, channels=3)\n",
    "        \n",
    "        # Default to using decode_image which works for most formats but does not return a shape statically\n",
    "        def decode_fallback():\n",
    "\n",
    "            image = tf.image.decode_image(image_data, channels=3, expand_animations=False)\n",
    "            print(\"Image shape:\", image.shape)\n",
    "\n",
    "            return image\n",
    "        \n",
    "        # Check the file extension and decode accordingly\n",
    "        image = tf.cond(\n",
    "            tf.strings.regex_full_match(file_path, \".*\\.jpeg$|.*\\.jpg$\"),\n",
    "            true_fn=decode_jpeg,\n",
    "            false_fn=lambda: tf.cond(\n",
    "                tf.strings.regex_full_match(file_path, \".*\\.png$\"),\n",
    "                true_fn=decode_png,\n",
    "                false_fn=decode_fallback\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        return image, label\n",
    "    except tf.errors.NotFoundError:\n",
    "        print(f\"Failed to load image at: {file_path}\")\n",
    "        return None, label\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image at: {file_path}\", str(e))\n",
    "        return None, label\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "full_dataset = tf.data.Dataset.from_tensor_slices((df['path'].tolist(), one_hot_encoded_labels))\n",
    "full_dataset = full_dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE) # This line of code applies the load_image function to each element in the full_dataset using the map method, with the num_parallel_calls argument set to tf.data.experimental.AUTOTUNE\n",
    "full_dataset = full_dataset.filter(lambda x, y: x is not None and y is not None) #clean dataset with clean data\n",
    "full_dataset = full_dataset.batch(16, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "'''\n",
    "Batching: full_dataset.batch(32): This transformation groups the dataset into batches of 32 elements each. This means that instead of processing individual elements, the dataset will now be processed in batches of 32 elements.\n",
    "Prefetching: .prefetch(tf.data.experimental.AUTOTUNE): This transformation prefetches a certain number of batches from the dataset and stores them in memory. By setting tf.data.experimental.AUTOTUNE, TensorFlow will automatically determine the optimal number of batches to prefetch based on the available resources (e.g., CPU, memory).\n",
    "'''\n",
    "\n",
    "# Split dataset into training and validation\n",
    "dataset_size = len(df)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "\n",
    "train_dataset = full_dataset.take(train_size)\n",
    "val_dataset = full_dataset.take(train_size)\n",
    "\n",
    "for images, labels in val_dataset.take(5):  # Take the first batch from the validation dataset\n",
    "    print(\"Images batch shape:\", images.shape)\n",
    "    print(\"Labels batch shape:\", labels.shape)\n",
    "    # Show the first image and label as an example\n",
    "    if images.shape[0] > 0:  # Check if there are any images in the batch\n",
    "        plt.imshow(images[0].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Sample Label: {labels[0].numpy()}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "def tf_model(num_classes):\n",
    "    print(\"num_classes value is:\", num_classes)\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(16, (3, 3), padding='same', input_shape=(224, 224, 3)),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(32, (3, 3), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), padding='same'),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64),\n",
    "        layers.LeakyReLU(alpha=0.1),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# this one 12 million parameters, trains a model and completes but with 500 records\n",
    "# def tf_model(num_classes):\n",
    "#     print(\"num_classes value is :\", num_classes)\n",
    "#     model = models.Sequential([\n",
    "#         layers.Conv2D(32, (3, 3), padding='same', input_shape=(224, 224, 3)),\n",
    "#         layers.LeakyReLU(alpha=0.1),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(64, (3, 3), padding='same'),\n",
    "#         layers.LeakyReLU(alpha=0.1),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Conv2D(128, (3, 3), padding='same'),\n",
    "#         layers.LeakyReLU(alpha=0.1),\n",
    "#         layers.MaxPooling2D((2, 2)),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(128),\n",
    "#         layers.LeakyReLU(alpha=0.1),\n",
    "#         layers.Dense(num_classes, activation='softmax')\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "class PerformanceCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start = time.time()\n",
    "        self.process = psutil.Process(os.getpid())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start\n",
    "        memory_usage = self.process.memory_info().rss / (1024 ** 2)  # Memory in MB\n",
    "        print(f\"Epoch {epoch+1} ended. Time: {epoch_time:.2f}s, Memory Usage: {memory_usage:.2f} MB\")\n",
    "        if 'val_loss' in logs:\n",
    "            print(f\"Validation Loss: {logs['val_loss']}\")\n",
    "\n",
    "model_name = \"Emotion_Detection_AI_20240803_205050_v1.h5\"\n",
    "\n",
    "local_model_path = f\"/tmp/{model_name}\"\n",
    "\n",
    "# Create a new directory for models if it doesn't exist\n",
    "model_dir = \"gs://storage_for_all/models\"\n",
    "full_model_path = f\"{model_dir}/{model_name}\"\n",
    "\n",
    "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
    "model = tf_model(num_classes)\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    local_model_path,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,\n",
    "    verbose=1  # Logs output whenever the model is saved.\n",
    ")\n",
    "\n",
    "# Define a custom callback to copy the model to GCS\n",
    "class CopyModelToGCS(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save the model locally\n",
    "        self.model.save(local_model_path, save_format='h5')\n",
    "\n",
    "        # Copy the model to Google Cloud Storage\n",
    "        gcs_model_path = f\"gs://storage_for_all/models/{model_name}\"\n",
    "        os.system(f\"gsutil cp {local_model_path} {gcs_model_path}\")\n",
    "\n",
    "        # Verify the model was copied\n",
    "        if tf.io.gfile.exists(gcs_model_path):\n",
    "            print(f\"Model saved successfully to {gcs_model_path}\")\n",
    "        else:\n",
    "            print(\"Failed to save the model to GCS\")\n",
    "\n",
    "# Create a list of callbacks\n",
    "callbacks = [checkpoint_callback, CopyModelToGCS()]\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# # Model training\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=10,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint_callback, PerformanceCallback()],\n",
    "    use_multiprocessing=True,\n",
    "    workers=3,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Model training\n",
    "# history = model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=10,\n",
    "#     validation_data=val_dataset,\n",
    "#     callbacks=[PerformanceCallback()],\n",
    "#     use_multiprocessing=True,\n",
    "#     workers=3,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# Plot training and validation accuracy and loss\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    if 'val_accuracy' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Save the model locally\n",
    "model.save(local_model_path, save_format='h5')\n",
    "\n",
    "# Copy the model to Google Cloud Storage\n",
    "gcs_model_path = f\"gs://storage_for_all/models/{model_name}\"\n",
    "os.system(f\"gsutil cp {local_model_path} {gcs_model_path}\")\n",
    "\n",
    "# Verify the model was copied\n",
    "if tf.io.gfile.exists(gcs_model_path):\n",
    "    print(f\"Model saved successfully to {gcs_model_path}\")\n",
    "else:\n",
    "    print(\"Failed to save the model to GCS\")\n",
    "\n",
    "    \n",
    "# Define the model name and GCS path\n",
    "#model_name = \"Emotion_Detection_AI_20240803_040927_v1.h5\"  # Replace with your actual model name\n",
    "\n",
    "gcs_model_path = f\"gs://storage_for_all/models/{model_name}\"\n",
    "local_model_path = f\"/tmp/{model_name}\"\n",
    "\n",
    "# Copy the model from GCS to local path\n",
    "os.system(f\"gsutil cp {gcs_model_path} {local_model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Verify the model was copied\n",
    "if not tf.io.gfile.exists(local_model_path):\n",
    "    print(\"Failed to load the model from GCS\")\n",
    "else:\n",
    "    print(f\"Model loaded successfully from {gcs_model_path}\")\n",
    "\n",
    "    # Load the model from local path\n",
    "    model = tf.keras.models.load_model(gcs_model_path)\n",
    "    print(\"Model loaded into TensorFlow\")\n",
    "    try:\n",
    "        # Evaluate the model on the validation dataset\n",
    "        loss, accuracy = model.evaluate(val_dataset)\n",
    "\n",
    "        # Print the evaluation results\n",
    "        print(f\"Test Loss: {loss:.3f}\")\n",
    "        print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model: {e}\")\n",
    "        \n",
    "\n",
    "    def predict_emotion(image_path):\n",
    "        image_data = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.expand_dims(image, 0)  # Make batch of 1\n",
    "\n",
    "        predictions = model.predict(image)\n",
    "        predicted_class = np.argmax(predictions[0])\n",
    "        emotion_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "        emotion_probabilities = predictions[0]\n",
    "\n",
    "        # Display the image with the predicted emotion and probabilities\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.imshow(image[0].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"Predicted Emotion: {emotion_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Emotion Probabilities:\")\n",
    "        for i, probability in enumerate(emotion_probabilities):\n",
    "            print(f\"{label_encoder.inverse_transform([i])[0]}: {probability:.2f}\")\n",
    "\n",
    "        return emotion_label, emotion_probabilities\n",
    "    # Example usage     \n",
    "    image_paths = [\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Happy/00a0084c2be84daa7b57c35c3e7563a62b716a71b6f1bc8c8aa577b5.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Happy/00a1e228b74ad9663ec8cb9aad62d0e1ed89d29f45c1a55efd73e0fa.JPG',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Happy/00b597a317f73e5832275a0a5f9aa8250f1a4450bd55ac20387f2c9d.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Sad/003b76ac33cfdfff858d3230ed1f3e56a75def52ae0d309a9f8cc169.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Sad/01b1763812bc6d9932343b0122aefff73ed1a0cce2f252f8b3a80546.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Angry/096f0eb818fd7021214c56995115cfa006a1893e5b9a9104f0c1fc96~angry.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Neutral/00aef13bc323b8abd5ec47a100132bc65c2a5e6e4136591e744f62b3f.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Neutral/00b1de6cda41141282f8a14da526cb2332eeb123c8185a7a9eaf30abf.jpg',\n",
    "        'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Neutral/00d6150365face753577d829406317a2c36cb11ff7be5146a9298cfcf.jpg',\n",
    "                 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Custom/img_sad.JPG',\n",
    " 'gs://storage_for_all/DataSets/FacialEmotionRecognitionImageDataset_v1/dataset/Custom/img_happy.JPG'\n",
    "    ]\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        predicted_emotion, emotion_probabilities = predict_emotion(image_path)\n",
    "        print(\"Image Path:\", image_path)\n",
    "        print(\"Predicted Emotion:\", predicted_emotion)\n",
    "        print(\"Emotion Probabilities:\", emotion_probabilities)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m122",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m122"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
